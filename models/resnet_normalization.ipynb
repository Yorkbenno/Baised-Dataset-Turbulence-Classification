{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "from MyDataset import MyDataset\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms, models\n",
    "from torch.nn import functional as F\n",
    "from tqdm.auto import tqdm\n",
    "# from PIL import Image\n",
    "import torchvision.models as models\n",
    "resnet18 = models.resnet18(pretrained=True)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    #transforms.ColorJitter(brightness=0.5, contrast=0.5, saturation=0.5),\n",
    "    transforms.RandomCrop(200),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.Normalize(mean = [0.5317,0.5026,0.5184,0.5190],std = [0.2617,0.2877,0.2941,0.2958]),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.Normalize(mean = [0.5317,0.5026,0.5184,0.5190],std = [0.2617,0.2877,0.2941,0.2958]),\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MyDataset(\"./train\",pre_transform)\n",
    "val_dataset = MyDataset(\"./validate\",val_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data length: 1754  valid data length  306\n"
     ]
    }
   ],
   "source": [
    "print(\"train data length: %d  valid data length % d\"%(len(train_dataset),len(val_dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Traning Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.5317) tensor(0.2617)\n",
      "tensor(0.5026) tensor(0.2877)\n",
      "tensor(0.5184) tensor(0.2941)\n",
      "tensor(0.5190) tensor(0.2958)\n"
     ]
    }
   ],
   "source": [
    "#Calculate the number of samples in differnet class\n",
    "train_nil_count = 0   ##591\n",
    "train_MOD_count = 0   ##839\n",
    "train_SEV_count = 0   ##324\n",
    "valid_nil_count = 0   ##192\n",
    "valid_MOD_count = 0   ##81\n",
    "valid_SEV_count = 0   ##33\n",
    "data0 = []\n",
    "data1 = []\n",
    "data2 = []\n",
    "data3 = []\n",
    "\n",
    "for i in range (0,1754):\n",
    "    #print(i)\n",
    "    img, label = train_dataset[i]\n",
    "    if (label == 0):\n",
    "        train_nil_count += 1\n",
    "        data0.append(img[0,:,:].numpy())\n",
    "        data1.append(img[1,:,:].numpy())\n",
    "        data2.append(img[2,:,:].numpy())\n",
    "        data3.append(img[3,:,:].numpy())\n",
    "    elif (label == 1):\n",
    "        train_MOD_count += 1\n",
    "        data0.append(img[0,:,:].numpy())\n",
    "        data1.append(img[1,:,:].numpy())\n",
    "        data2.append(img[2,:,:].numpy())\n",
    "        data3.append(img[3,:,:].numpy())\n",
    "    else:\n",
    "        train_SEV_count += 1\n",
    "        data0.append(img[0,:,:].numpy())\n",
    "        data1.append(img[1,:,:].numpy())\n",
    "        data2.append(img[2,:,:].numpy())\n",
    "        data3.append(img[3,:,:].numpy())\n",
    "# print(\"train set has %d nil, %d MOD, %d SEV\" %(train_nil_count, train_MOD_count, train_SEV_count))\n",
    "data0 = torch.Tensor(data0)\n",
    "data1 = torch.Tensor(data1)\n",
    "data2 = torch.Tensor(data2)\n",
    "data3 = torch.Tensor(data3)\n",
    "print(torch.mean(data0), torch.std(data0))\n",
    "print(torch.mean(data1), torch.std(data1))\n",
    "print(torch.mean(data2), torch.std(data2))\n",
    "print(torch.mean(data3), torch.std(data3))\n",
    "# for i in range (0,306):\n",
    "#     #print(i)\n",
    "#     img, label = val_dataset[i]\n",
    "#     if (label == 0):\n",
    "#         valid_nil_count += 1\n",
    "#     elif (label == 1):\n",
    "#         valid_MOD_count += 1\n",
    "#     else:\n",
    "#         valid_SEV_count += 1\n",
    "# print(\"valid set has %d nil, %d MOD, %d SEV\" %(valid_nil_count, valid_MOD_count, valid_SEV_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False),\n",
       " BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       " ReLU(inplace=True),\n",
       " MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False),\n",
       " Sequential(\n",
       "   (0): BasicBlock(\n",
       "     (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (relu): ReLU(inplace=True)\n",
       "     (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   )\n",
       "   (1): BasicBlock(\n",
       "     (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (relu): ReLU(inplace=True)\n",
       "     (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   )\n",
       " ),\n",
       " Sequential(\n",
       "   (0): BasicBlock(\n",
       "     (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "     (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (relu): ReLU(inplace=True)\n",
       "     (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (downsample): Sequential(\n",
       "       (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "       (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     )\n",
       "   )\n",
       "   (1): BasicBlock(\n",
       "     (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (relu): ReLU(inplace=True)\n",
       "     (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   )\n",
       " ),\n",
       " Sequential(\n",
       "   (0): BasicBlock(\n",
       "     (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "     (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (relu): ReLU(inplace=True)\n",
       "     (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (downsample): Sequential(\n",
       "       (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "       (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     )\n",
       "   )\n",
       "   (1): BasicBlock(\n",
       "     (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (relu): ReLU(inplace=True)\n",
       "     (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   )\n",
       " ),\n",
       " Sequential(\n",
       "   (0): BasicBlock(\n",
       "     (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "     (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (relu): ReLU(inplace=True)\n",
       "     (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (downsample): Sequential(\n",
       "       (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "       (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     )\n",
       "   )\n",
       "   (1): BasicBlock(\n",
       "     (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (relu): ReLU(inplace=True)\n",
       "     (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "     (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   )\n",
       " ),\n",
       " AdaptiveAvgPool2d(output_size=(1, 1)),\n",
       " Linear(in_features=512, out_features=1000, bias=True)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(resnet18.children())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Model & Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1  = nn.Conv2d(4, 3, 3, 1, 1)\n",
    "        self.bn = nn.BatchNorm2d(3)\n",
    "        self.extractor = nn.Sequential(*list(resnet18.children())[:-2]).cuda()\n",
    "        for param in list(self.extractor.parameters()):\n",
    "            param.requires_grad = False\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(512,512,3,1,1)\n",
    "        \n",
    "        self.fc1 = nn.Linear(4608, 128)\n",
    "        self.fc2 = nn.Linear(128, 3)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.extractor(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv3(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        #print(x.shape)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        #x = F.relu(x)\n",
    "        #output = F.softmax(x, dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True, pin_memory=False)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=64, shuffle=True, pin_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(4, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (bn): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (extractor): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    (4): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (5): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (6): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (7): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (conv3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (fc1): Linear(in_features=4608, out_features=128, bias=True)\n",
      "  (fc2): Linear(in_features=128, out_features=3, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = Net()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[[[ 0.1142,  0.1326, -0.0717],\n",
      "          [ 0.1366, -0.0746,  0.1468],\n",
      "          [ 0.0350, -0.0177,  0.0857]],\n",
      "\n",
      "         [[-0.0311, -0.0241, -0.0331],\n",
      "          [-0.1410,  0.1151, -0.0688],\n",
      "          [ 0.1520,  0.1110,  0.0394]],\n",
      "\n",
      "         [[-0.1446,  0.0008,  0.1141],\n",
      "          [-0.0282,  0.1605, -0.1260],\n",
      "          [-0.0076, -0.0824,  0.0051]],\n",
      "\n",
      "         [[ 0.1333,  0.1030, -0.1565],\n",
      "          [ 0.0942, -0.0863, -0.0346],\n",
      "          [ 0.1514, -0.0193, -0.1605]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1620, -0.0949,  0.0730],\n",
      "          [ 0.0598,  0.1555,  0.1646],\n",
      "          [-0.0886, -0.0005, -0.0310]],\n",
      "\n",
      "         [[-0.0124, -0.1331,  0.0090],\n",
      "          [ 0.0006, -0.1298,  0.0321],\n",
      "          [ 0.0926,  0.0675,  0.0179]],\n",
      "\n",
      "         [[-0.1198, -0.1194,  0.0807],\n",
      "          [ 0.0664, -0.1171, -0.0636],\n",
      "          [-0.1131, -0.0069, -0.0622]],\n",
      "\n",
      "         [[ 0.0755, -0.1205,  0.1654],\n",
      "          [-0.0928, -0.1581, -0.0940],\n",
      "          [ 0.1609, -0.0143,  0.0594]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0641, -0.1234,  0.0178],\n",
      "          [ 0.1373,  0.0840,  0.1555],\n",
      "          [ 0.1525, -0.0783,  0.1569]],\n",
      "\n",
      "         [[-0.1226, -0.1037,  0.0079],\n",
      "          [-0.0662, -0.1039,  0.0117],\n",
      "          [-0.0157, -0.1602, -0.1405]],\n",
      "\n",
      "         [[-0.0486,  0.0037, -0.0972],\n",
      "          [ 0.0135,  0.0177,  0.0770],\n",
      "          [ 0.0160, -0.0670, -0.0163]],\n",
      "\n",
      "         [[ 0.0649, -0.0010,  0.0612],\n",
      "          [ 0.0167,  0.0425,  0.0204],\n",
      "          [ 0.1572,  0.1569,  0.0955]]]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0940, -0.0290,  0.0048], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([1., 1., 1.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[[[-0.0002, -0.0098,  0.0038],\n",
      "          [-0.0030,  0.0024, -0.0111],\n",
      "          [-0.0118, -0.0037, -0.0106]],\n",
      "\n",
      "         [[-0.0115,  0.0061, -0.0105],\n",
      "          [-0.0006,  0.0097,  0.0077],\n",
      "          [ 0.0002, -0.0103,  0.0123]],\n",
      "\n",
      "         [[ 0.0122, -0.0126,  0.0087],\n",
      "          [ 0.0046,  0.0058, -0.0069],\n",
      "          [ 0.0111, -0.0105, -0.0012]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0050,  0.0067, -0.0099],\n",
      "          [-0.0070,  0.0061, -0.0115],\n",
      "          [ 0.0036, -0.0117, -0.0135]],\n",
      "\n",
      "         [[ 0.0007, -0.0126,  0.0022],\n",
      "          [ 0.0043,  0.0007,  0.0011],\n",
      "          [ 0.0108, -0.0139,  0.0082]],\n",
      "\n",
      "         [[-0.0127,  0.0143,  0.0053],\n",
      "          [ 0.0088,  0.0144, -0.0059],\n",
      "          [ 0.0012, -0.0093, -0.0121]]],\n",
      "\n",
      "\n",
      "        [[[-0.0003,  0.0068, -0.0107],\n",
      "          [-0.0109,  0.0004, -0.0079],\n",
      "          [ 0.0028,  0.0007,  0.0038]],\n",
      "\n",
      "         [[-0.0088,  0.0041,  0.0040],\n",
      "          [ 0.0102,  0.0094,  0.0040],\n",
      "          [-0.0032, -0.0034, -0.0107]],\n",
      "\n",
      "         [[-0.0070, -0.0104,  0.0038],\n",
      "          [-0.0018, -0.0110, -0.0147],\n",
      "          [-0.0037,  0.0002, -0.0006]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0039, -0.0017,  0.0057],\n",
      "          [-0.0051,  0.0080, -0.0075],\n",
      "          [-0.0038, -0.0039,  0.0134]],\n",
      "\n",
      "         [[-0.0053, -0.0015,  0.0086],\n",
      "          [-0.0045, -0.0057,  0.0030],\n",
      "          [-0.0145, -0.0058,  0.0135]],\n",
      "\n",
      "         [[ 0.0089, -0.0095, -0.0009],\n",
      "          [-0.0016,  0.0062,  0.0139],\n",
      "          [-0.0120,  0.0058,  0.0011]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0037, -0.0065,  0.0061],\n",
      "          [-0.0009,  0.0027, -0.0102],\n",
      "          [-0.0135, -0.0118,  0.0063]],\n",
      "\n",
      "         [[ 0.0013,  0.0046, -0.0012],\n",
      "          [-0.0059, -0.0079,  0.0062],\n",
      "          [-0.0023, -0.0120,  0.0066]],\n",
      "\n",
      "         [[ 0.0124, -0.0120,  0.0042],\n",
      "          [-0.0146, -0.0095,  0.0004],\n",
      "          [-0.0037,  0.0108,  0.0071]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0119,  0.0014, -0.0025],\n",
      "          [ 0.0096, -0.0030, -0.0109],\n",
      "          [-0.0106,  0.0072,  0.0120]],\n",
      "\n",
      "         [[ 0.0048, -0.0052,  0.0127],\n",
      "          [-0.0146,  0.0119,  0.0083],\n",
      "          [ 0.0033,  0.0015, -0.0051]],\n",
      "\n",
      "         [[ 0.0085,  0.0075, -0.0071],\n",
      "          [-0.0021,  0.0015,  0.0037],\n",
      "          [ 0.0011, -0.0139, -0.0087]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0116,  0.0100, -0.0012],\n",
      "          [ 0.0071,  0.0070, -0.0096],\n",
      "          [ 0.0098, -0.0143, -0.0011]],\n",
      "\n",
      "         [[ 0.0034,  0.0119, -0.0118],\n",
      "          [-0.0007,  0.0062,  0.0063],\n",
      "          [ 0.0016, -0.0013, -0.0096]],\n",
      "\n",
      "         [[-0.0024,  0.0124, -0.0017],\n",
      "          [-0.0004, -0.0051,  0.0046],\n",
      "          [-0.0139, -0.0138,  0.0144]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0132,  0.0036,  0.0086],\n",
      "          [ 0.0048, -0.0071, -0.0014],\n",
      "          [-0.0014, -0.0030, -0.0141]],\n",
      "\n",
      "         [[ 0.0080, -0.0146,  0.0054],\n",
      "          [-0.0020, -0.0101,  0.0118],\n",
      "          [ 0.0070,  0.0051, -0.0062]],\n",
      "\n",
      "         [[ 0.0142, -0.0086, -0.0012],\n",
      "          [-0.0009, -0.0055,  0.0024],\n",
      "          [-0.0118, -0.0030, -0.0038]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0010,  0.0029, -0.0075],\n",
      "          [ 0.0015,  0.0033,  0.0147],\n",
      "          [-0.0100,  0.0004, -0.0141]],\n",
      "\n",
      "         [[ 0.0102,  0.0044, -0.0011],\n",
      "          [ 0.0068, -0.0110,  0.0051],\n",
      "          [ 0.0137, -0.0095, -0.0079]],\n",
      "\n",
      "         [[ 0.0073,  0.0058,  0.0069],\n",
      "          [ 0.0136,  0.0095, -0.0050],\n",
      "          [-0.0025, -0.0014, -0.0137]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0028,  0.0113,  0.0046],\n",
      "          [-0.0077,  0.0070,  0.0018],\n",
      "          [-0.0130, -0.0081,  0.0145]],\n",
      "\n",
      "         [[-0.0063, -0.0089, -0.0011],\n",
      "          [-0.0058,  0.0028,  0.0080],\n",
      "          [-0.0098, -0.0008, -0.0077]],\n",
      "\n",
      "         [[-0.0090,  0.0133, -0.0112],\n",
      "          [-0.0106, -0.0090, -0.0095],\n",
      "          [ 0.0065, -0.0011,  0.0071]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0086, -0.0128, -0.0129],\n",
      "          [ 0.0055,  0.0067,  0.0134],\n",
      "          [-0.0147, -0.0029,  0.0102]],\n",
      "\n",
      "         [[ 0.0005,  0.0039, -0.0024],\n",
      "          [-0.0089, -0.0025, -0.0013],\n",
      "          [ 0.0016, -0.0069,  0.0114]],\n",
      "\n",
      "         [[ 0.0037, -0.0070,  0.0075],\n",
      "          [-0.0128,  0.0104, -0.0101],\n",
      "          [ 0.0037, -0.0093, -0.0093]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0122,  0.0112, -0.0023],\n",
      "          [-0.0040,  0.0058, -0.0017],\n",
      "          [-0.0004, -0.0096,  0.0091]],\n",
      "\n",
      "         [[ 0.0006,  0.0065, -0.0074],\n",
      "          [ 0.0099, -0.0141,  0.0112],\n",
      "          [ 0.0085, -0.0106, -0.0050]],\n",
      "\n",
      "         [[-0.0112,  0.0062,  0.0099],\n",
      "          [ 0.0084,  0.0056, -0.0126],\n",
      "          [ 0.0108, -0.0011, -0.0030]]]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-8.2266e-03,  4.6808e-03,  9.8865e-03,  5.0852e-03, -2.1109e-03,\n",
      "        -3.0937e-03, -9.6644e-04,  9.4859e-03,  7.9100e-04, -3.5135e-03,\n",
      "         6.6490e-03, -1.3627e-02,  2.4816e-03, -1.3996e-02,  8.2689e-04,\n",
      "         1.0954e-02, -1.3140e-02, -1.4215e-02, -1.2108e-02, -4.7640e-03,\n",
      "         1.8126e-03,  1.0604e-02, -7.7347e-03,  1.0986e-02, -1.2667e-02,\n",
      "        -7.0568e-03, -6.0602e-03, -3.3863e-03,  6.3948e-03,  5.3797e-03,\n",
      "         8.2940e-03,  5.9177e-03,  1.0660e-02,  5.3362e-03, -1.0725e-03,\n",
      "        -1.6440e-03, -1.1393e-02,  1.2391e-02,  1.3082e-02,  3.4587e-03,\n",
      "        -7.0649e-03,  8.2117e-03,  7.4127e-03,  1.2990e-02,  1.4109e-02,\n",
      "        -2.9357e-03,  4.9497e-03, -4.8255e-03, -3.2446e-03, -2.7198e-03,\n",
      "        -7.2242e-03, -6.7590e-04,  7.7125e-03,  7.3234e-03,  7.9413e-03,\n",
      "        -1.2419e-02,  1.2294e-03,  9.0595e-03, -1.3071e-02, -1.2957e-02,\n",
      "        -1.2607e-02, -8.1316e-03,  1.4706e-02,  1.5539e-03, -1.4629e-02,\n",
      "         9.2644e-03,  4.4465e-03, -8.5142e-03,  3.8995e-03,  5.9462e-03,\n",
      "        -2.3441e-03,  1.0283e-02, -4.7597e-03, -8.3213e-03,  1.3278e-02,\n",
      "         2.1317e-03,  4.7778e-03,  9.6185e-03,  1.0547e-02,  5.2382e-03,\n",
      "         1.2028e-02,  4.6604e-03,  1.2007e-03, -1.3628e-02,  4.7743e-03,\n",
      "        -1.0016e-02, -1.0055e-02,  1.0862e-02, -5.6067e-03, -7.3917e-03,\n",
      "         3.6779e-04, -2.3340e-03,  1.1551e-02,  1.2898e-02,  6.5200e-04,\n",
      "        -5.0432e-03,  2.8042e-03, -1.5941e-03, -5.4381e-03,  8.4623e-03,\n",
      "         1.1909e-02,  5.1464e-03, -1.4584e-02,  3.0083e-03,  2.4868e-03,\n",
      "        -3.9961e-03,  1.3041e-02, -4.5153e-03,  7.5304e-03,  8.8897e-03,\n",
      "        -1.2935e-02, -6.5149e-03,  2.3067e-03,  1.0758e-02, -7.0523e-03,\n",
      "        -1.2225e-02, -1.3306e-02,  2.6873e-03, -1.2678e-02, -4.5297e-03,\n",
      "         7.3839e-03,  8.7958e-03, -3.2913e-03,  1.1226e-02,  1.1698e-02,\n",
      "         9.8083e-03,  1.4496e-02,  1.3374e-03, -7.1151e-03,  1.2801e-02,\n",
      "         8.3506e-03,  1.1006e-03, -1.3133e-02,  1.1828e-02, -1.9006e-03,\n",
      "        -1.2904e-02,  7.4430e-03,  7.3413e-03,  8.3533e-03, -1.2015e-02,\n",
      "        -4.8732e-03,  7.4102e-03,  7.3194e-03,  1.5971e-03,  1.2776e-02,\n",
      "        -6.9389e-04,  7.8433e-03,  6.7393e-03, -1.0851e-02,  1.1120e-02,\n",
      "        -1.0649e-02, -1.5709e-04,  1.0205e-02,  9.6066e-03,  4.4957e-03,\n",
      "        -2.8056e-03, -5.3367e-03,  2.7956e-03,  7.1500e-03,  1.3846e-02,\n",
      "         4.9554e-03,  1.0964e-02,  3.8781e-04,  1.1674e-02, -8.2686e-03,\n",
      "         5.5574e-03, -2.3614e-04, -3.6804e-03,  1.2525e-02,  7.9983e-03,\n",
      "         1.0909e-02, -8.8744e-03, -6.0846e-03,  8.9804e-04, -7.8093e-03,\n",
      "        -1.1267e-02, -6.7054e-04,  9.9076e-03,  1.2650e-02, -6.9370e-03,\n",
      "        -1.0424e-02, -6.1949e-03, -8.3751e-03,  4.6626e-03,  6.0100e-03,\n",
      "         9.6443e-03,  3.8583e-04, -1.7754e-03,  1.3895e-02,  9.4437e-03,\n",
      "        -9.0757e-03, -5.1057e-03, -7.9531e-03,  1.0309e-02, -1.4262e-02,\n",
      "        -4.8768e-03,  1.9606e-03,  1.2095e-02, -1.0527e-02,  1.1486e-02,\n",
      "         6.0821e-03, -5.4107e-03, -4.0786e-03, -6.4181e-03, -7.9114e-04,\n",
      "         4.9056e-03,  5.3021e-03,  9.2563e-03,  1.0968e-02,  5.3873e-03,\n",
      "         1.3350e-02, -5.9063e-03,  5.1608e-03, -6.7195e-03,  4.6772e-03,\n",
      "         1.1109e-02, -2.0927e-03,  8.0597e-03, -6.5916e-03, -5.7543e-03,\n",
      "         1.4230e-02, -1.3447e-02, -5.3511e-03, -2.8537e-03,  2.2691e-04,\n",
      "         1.0263e-02, -8.7388e-03,  8.7379e-03,  2.7326e-03,  3.5278e-03,\n",
      "        -1.0789e-02,  9.0513e-03, -6.0824e-03,  8.4881e-03, -1.4263e-04,\n",
      "         1.1392e-02,  9.4778e-03, -9.8060e-04,  8.7589e-03,  8.5681e-03,\n",
      "         5.0187e-03,  3.5958e-03, -1.0141e-02,  1.2272e-02,  9.3240e-03,\n",
      "         6.1853e-03,  3.9695e-03,  1.3436e-02, -4.1609e-03,  6.2978e-03,\n",
      "         3.6387e-03, -7.0360e-03, -1.3985e-02,  7.3220e-03, -5.3155e-03,\n",
      "        -5.5873e-03,  2.3219e-03, -7.6742e-03,  7.8723e-03, -3.7597e-03,\n",
      "         1.7611e-04,  5.8842e-03,  8.2593e-04, -2.4088e-03, -4.0885e-03,\n",
      "        -7.6591e-03, -4.7460e-03,  8.7123e-03,  1.4208e-02,  1.3716e-02,\n",
      "        -1.2975e-02, -1.2207e-03, -5.9467e-03,  9.2058e-03, -5.7665e-03,\n",
      "         1.3651e-02,  7.6314e-03, -1.0829e-02,  1.2161e-02, -5.9509e-03,\n",
      "         1.1205e-02,  7.9863e-03, -1.0029e-02,  9.8460e-03,  1.4718e-03,\n",
      "        -9.4274e-03,  1.2110e-02, -7.5247e-04,  2.9127e-03,  1.1176e-02,\n",
      "         1.0721e-02, -1.2924e-03,  9.1694e-04, -2.7134e-03,  9.3080e-03,\n",
      "        -2.2739e-03, -5.2072e-03,  6.2418e-03, -2.1943e-03, -7.4259e-03,\n",
      "        -5.0476e-03, -3.7571e-03,  3.2948e-03,  9.1931e-03, -9.7182e-04,\n",
      "        -1.4407e-03, -7.7343e-03,  8.1590e-03,  8.8701e-03,  1.3985e-02,\n",
      "         1.3569e-02,  1.0399e-03,  4.8964e-03,  5.0092e-03,  6.7521e-03,\n",
      "        -6.3757e-03,  2.6952e-03, -1.0674e-05, -1.0186e-02,  9.3276e-03,\n",
      "        -8.1935e-03,  5.7221e-03,  1.0159e-02, -3.9526e-03, -2.0616e-04,\n",
      "         2.5697e-03,  1.1584e-02, -9.5804e-03, -9.8275e-03, -1.0462e-02,\n",
      "         1.4019e-03,  1.4610e-02, -3.2005e-03, -1.0529e-02,  1.2511e-02,\n",
      "        -7.0836e-03, -4.3214e-03, -7.7998e-03,  1.2881e-02, -9.8808e-04,\n",
      "         8.3269e-03,  1.7726e-03,  5.0231e-03,  1.5675e-03, -1.1186e-02,\n",
      "        -5.8353e-03, -2.1581e-03,  5.4528e-03, -2.0605e-03, -7.5531e-03,\n",
      "         1.2923e-02,  1.4513e-02,  6.8940e-03, -1.1022e-02, -7.2503e-03,\n",
      "        -1.2077e-02, -9.3168e-03,  1.1587e-02, -1.2491e-02, -7.2250e-03,\n",
      "         1.3474e-02, -5.9315e-03,  9.9475e-03,  9.0963e-03,  8.5107e-03,\n",
      "         7.5595e-03,  2.2626e-03,  3.8685e-03,  6.4225e-03, -1.4470e-02,\n",
      "        -1.2876e-02, -1.9068e-03, -2.4675e-03,  8.0885e-03,  1.1839e-02,\n",
      "        -1.0764e-02,  1.9978e-03, -1.8452e-03,  5.6683e-03, -9.3848e-03,\n",
      "         6.4088e-03,  1.4042e-02,  3.6043e-03,  1.0363e-02,  1.1198e-02,\n",
      "        -3.8669e-03, -1.3740e-02,  1.0092e-02, -1.1731e-02,  8.5324e-03,\n",
      "         1.4031e-02,  7.1483e-03, -8.3393e-03, -6.7747e-03, -4.9592e-03,\n",
      "         1.2561e-02, -6.4974e-03, -1.0175e-02, -8.7471e-03,  6.8489e-03,\n",
      "         1.6833e-05, -1.1934e-02, -1.0943e-02, -1.0033e-02,  1.3531e-02,\n",
      "         1.2319e-02, -1.0202e-02,  2.6771e-03, -6.2901e-03, -8.5482e-03,\n",
      "         5.2783e-03, -8.6481e-03, -3.1892e-04,  8.5373e-04,  1.4693e-02,\n",
      "        -4.8127e-03,  1.2466e-02,  2.7916e-03, -6.0461e-03, -1.3515e-02,\n",
      "         1.8086e-03,  8.6707e-03, -9.9332e-03, -1.3433e-03,  2.6308e-03,\n",
      "        -4.6610e-03,  3.8226e-03,  2.1826e-03, -2.5846e-03, -4.4183e-03,\n",
      "        -1.3832e-02,  4.9865e-03, -4.0115e-03,  9.7572e-03,  6.5841e-04,\n",
      "        -3.7475e-03,  6.4491e-03, -1.0013e-02,  2.7763e-03,  1.1822e-02,\n",
      "        -9.9844e-03, -1.1278e-02,  6.0642e-03, -1.1202e-02,  1.0147e-02,\n",
      "         5.6876e-03,  1.4717e-02,  1.3875e-02,  5.2423e-03, -6.5177e-03,\n",
      "        -9.9228e-03,  7.1808e-03, -7.5622e-03,  8.8223e-03, -1.1397e-02,\n",
      "        -1.2224e-02, -1.2701e-03,  1.4327e-02,  1.7725e-03,  2.1840e-03,\n",
      "         1.0279e-02,  8.0803e-03,  1.1585e-02,  1.0792e-02, -9.1133e-03,\n",
      "        -7.7137e-03, -4.8257e-03, -1.3664e-02, -1.1113e-02,  1.3442e-02,\n",
      "         1.3922e-02, -6.0433e-04,  7.3404e-03,  1.2289e-02, -4.2412e-03,\n",
      "         1.4314e-02,  1.3586e-02, -1.3741e-02,  6.8351e-03, -1.2072e-02,\n",
      "        -1.3656e-02,  5.9769e-03, -1.5787e-03,  2.8166e-03,  9.9903e-03,\n",
      "         5.1122e-03, -5.8105e-03,  7.5577e-03, -8.5875e-03,  8.1569e-03,\n",
      "        -6.3709e-03, -1.1149e-02, -3.1640e-03,  4.2815e-03, -1.3883e-03,\n",
      "        -9.1962e-04,  1.2756e-02,  3.1034e-03, -1.2053e-03,  1.5859e-03,\n",
      "        -3.6498e-03, -2.3308e-03, -1.2471e-02,  9.2661e-03,  3.9078e-03,\n",
      "        -5.8844e-03, -1.7739e-03, -1.2295e-02,  1.9377e-03,  1.1366e-02,\n",
      "        -1.0029e-02, -3.4218e-03], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0100,  0.0106,  0.0005,  ..., -0.0024, -0.0027,  0.0017],\n",
      "        [ 0.0082, -0.0049,  0.0073,  ...,  0.0022, -0.0034, -0.0076],\n",
      "        [-0.0077,  0.0056,  0.0134,  ..., -0.0119,  0.0084,  0.0028],\n",
      "        ...,\n",
      "        [ 0.0017, -0.0089, -0.0006,  ..., -0.0030,  0.0043, -0.0055],\n",
      "        [-0.0083,  0.0044,  0.0086,  ..., -0.0015, -0.0013,  0.0124],\n",
      "        [ 0.0050,  0.0143, -0.0133,  ..., -0.0106, -0.0007, -0.0058]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 1.2108e-02,  9.4067e-03,  5.2740e-03,  8.2382e-04,  8.4931e-03,\n",
      "        -4.9570e-03, -1.3401e-02, -3.7977e-03, -4.3093e-03,  3.9689e-03,\n",
      "        -5.2637e-03, -3.1991e-03, -1.0348e-02,  6.2953e-03,  5.0781e-03,\n",
      "         1.0570e-02,  8.7816e-03, -1.3053e-02, -4.7753e-04, -5.6280e-03,\n",
      "        -9.9952e-03, -9.6046e-03, -3.8504e-03,  4.5653e-03, -1.0901e-02,\n",
      "        -6.8727e-03, -4.0228e-03,  1.1656e-03,  2.2163e-03, -4.2144e-03,\n",
      "        -1.3832e-02,  2.8898e-03,  1.4950e-03, -5.8551e-03,  9.1752e-05,\n",
      "        -1.4190e-02,  1.0558e-02, -9.4802e-03, -4.2372e-03, -1.3435e-02,\n",
      "         1.3893e-02, -4.3045e-03, -1.1589e-02, -9.6426e-03, -7.3204e-04,\n",
      "        -8.1135e-03,  4.6139e-03,  5.2927e-03, -8.4057e-03, -1.2506e-02,\n",
      "         3.4073e-03,  1.2031e-02, -1.3938e-02, -1.4375e-02, -7.0549e-03,\n",
      "        -2.3719e-03, -5.9935e-03,  1.4922e-03,  1.7307e-04,  1.3407e-02,\n",
      "         1.3790e-02,  8.9539e-03,  1.1817e-02,  1.9542e-04,  1.1450e-02,\n",
      "        -6.9206e-03,  1.2820e-02, -6.7063e-03,  2.9981e-03, -7.2330e-03,\n",
      "        -1.0361e-02,  2.7311e-03,  1.3326e-02,  1.2141e-02, -1.3840e-02,\n",
      "        -8.0213e-03, -1.3542e-02, -4.8496e-03, -2.9519e-04,  9.1600e-04,\n",
      "         1.2614e-02, -1.0639e-02, -1.1654e-02, -1.1709e-02, -7.3049e-03,\n",
      "        -7.5945e-04, -1.0500e-02, -6.0018e-03, -3.6992e-03, -1.0221e-03,\n",
      "        -8.2500e-03, -1.3673e-02,  6.9631e-03,  8.9050e-03,  1.3363e-02,\n",
      "        -8.4748e-03,  5.5408e-03, -7.6088e-03,  1.3524e-02, -9.1218e-03,\n",
      "         7.9419e-04, -5.6891e-03,  1.9906e-03,  4.4247e-03, -2.2346e-03,\n",
      "         2.8040e-03,  7.2236e-03,  1.1104e-02, -2.2917e-03, -1.0020e-02,\n",
      "         7.7619e-03,  4.1713e-03,  8.6906e-03,  2.3296e-03,  1.1673e-02,\n",
      "        -1.0536e-02, -1.1443e-02,  1.0630e-02, -3.2536e-03,  4.6766e-03,\n",
      "         3.9624e-03, -5.5548e-03,  4.8781e-03,  9.0543e-03,  1.3031e-02,\n",
      "        -4.0887e-03,  4.8834e-03, -1.3966e-02], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 4.0620e-02, -6.3463e-02,  1.1437e-02,  1.0136e-02,  5.9064e-02,\n",
      "          1.1821e-02,  2.9847e-02, -4.6102e-02, -6.3180e-02, -4.8313e-02,\n",
      "          1.9158e-02,  2.0592e-02,  8.4662e-02, -3.3391e-02, -8.2722e-02,\n",
      "         -3.8801e-02,  7.6033e-02, -7.5716e-02, -8.4693e-03, -1.4611e-02,\n",
      "         -2.8315e-02, -1.3110e-02,  2.1880e-02,  8.7811e-02,  8.4069e-02,\n",
      "          4.2295e-02,  3.3519e-02, -4.0797e-02,  2.8537e-02,  3.5448e-03,\n",
      "          2.9416e-02, -1.0047e-02, -7.4896e-02, -5.2462e-02, -4.3944e-02,\n",
      "          8.2912e-02, -2.3158e-02,  5.3447e-02,  4.8716e-02, -3.4082e-02,\n",
      "          1.6198e-02,  7.0190e-02, -1.9805e-02,  3.7951e-02, -2.9244e-02,\n",
      "         -5.8004e-02,  5.2427e-02, -6.8715e-03,  2.7017e-02,  7.2076e-02,\n",
      "          2.6873e-02, -4.1093e-02, -7.3200e-02,  1.1498e-02,  4.9361e-02,\n",
      "          7.6679e-02,  4.6930e-02, -8.2965e-02, -3.5373e-02, -6.5663e-02,\n",
      "          4.9609e-03,  3.0871e-02, -6.8548e-02,  6.4918e-02,  7.7021e-02,\n",
      "          6.5618e-02,  2.9395e-02, -8.7540e-02, -4.7985e-03, -3.1213e-02,\n",
      "          7.2812e-02, -5.2543e-02, -6.2930e-02,  5.2492e-02,  2.0411e-02,\n",
      "          1.8403e-02, -1.9813e-02, -6.7621e-02,  8.3995e-02,  4.9764e-02,\n",
      "         -6.4101e-02, -6.3057e-02,  2.3454e-02,  6.2842e-02,  7.7406e-02,\n",
      "          1.4777e-02, -1.5830e-02,  7.0114e-03, -2.8438e-02, -7.4515e-02,\n",
      "         -5.7344e-02,  1.7453e-02,  2.7141e-03,  7.9007e-02,  5.2876e-02,\n",
      "          4.4397e-02,  3.5891e-02,  5.7219e-03, -6.5764e-02,  7.6049e-02,\n",
      "          8.8040e-02,  7.7202e-02,  5.3673e-04,  6.1659e-02, -3.6603e-02,\n",
      "         -1.0653e-02, -7.5147e-02, -8.2150e-02, -6.0409e-02, -7.2637e-02,\n",
      "         -1.5112e-02,  3.7826e-02,  1.7403e-03, -5.3177e-04, -5.3699e-02,\n",
      "         -6.1150e-02,  6.5361e-03,  3.0876e-02,  5.0590e-02,  6.1368e-03,\n",
      "         -2.0214e-02, -8.1352e-02, -6.4557e-02,  3.9297e-02,  6.8234e-02,\n",
      "         -5.1606e-02, -6.5866e-02, -1.8697e-02],\n",
      "        [ 3.9481e-02, -8.1975e-02,  6.7859e-02, -3.0835e-02, -6.8428e-02,\n",
      "          5.1115e-02, -2.9464e-03, -5.2045e-02,  2.2490e-02,  3.5976e-02,\n",
      "         -2.7872e-02, -2.2663e-02, -8.7948e-02,  2.4740e-03,  2.9727e-02,\n",
      "         -5.3089e-02,  8.2675e-02,  4.6561e-03, -5.8507e-02,  8.8331e-02,\n",
      "          8.3688e-02,  5.5017e-02, -2.8246e-02,  2.9909e-02, -6.7213e-03,\n",
      "         -3.2540e-02, -4.7765e-02,  1.1836e-03,  5.0213e-02,  8.7593e-02,\n",
      "         -6.1352e-02,  3.6972e-02, -1.7303e-02, -7.3095e-02,  4.7511e-02,\n",
      "          4.1186e-02,  4.6701e-02, -2.1600e-02, -7.6508e-02, -3.2505e-02,\n",
      "         -5.4599e-02,  3.0655e-03,  5.4948e-03, -9.5164e-03,  1.5871e-02,\n",
      "          3.2120e-02, -7.5979e-02,  8.4849e-02,  8.2294e-02,  7.0902e-02,\n",
      "          7.8365e-02, -7.4549e-04,  2.1670e-02,  5.8538e-02, -7.7312e-02,\n",
      "          2.0309e-02,  4.1857e-02,  7.3995e-02, -8.3329e-02, -8.5476e-02,\n",
      "         -7.4887e-02,  6.8327e-02, -5.2733e-02,  3.5279e-02,  1.8387e-02,\n",
      "          6.6108e-02, -4.9611e-02,  2.5719e-02,  6.2447e-02, -5.5424e-02,\n",
      "          5.3857e-02, -1.5221e-02, -8.1238e-02,  4.6507e-02, -1.4104e-02,\n",
      "          6.5305e-02, -8.8333e-03, -3.3703e-02,  3.5525e-02, -2.6714e-02,\n",
      "         -4.4178e-02, -4.6657e-03, -5.6606e-02, -4.2794e-02,  4.0249e-02,\n",
      "         -4.1719e-02, -4.6416e-02,  8.1343e-02,  7.7762e-02, -8.1137e-02,\n",
      "         -7.8144e-02, -7.4481e-02,  4.6527e-02, -7.8762e-03,  2.9425e-02,\n",
      "         -5.9443e-02, -4.9541e-02, -1.6041e-02, -8.0721e-02,  6.9341e-02,\n",
      "          2.2080e-02,  4.4941e-02,  5.4839e-02, -6.4309e-02,  6.0381e-02,\n",
      "         -2.6945e-02,  5.3920e-02, -1.1108e-02,  5.7129e-02,  3.8646e-02,\n",
      "         -7.0823e-02, -3.4989e-02, -8.7864e-02, -7.1301e-02,  6.6447e-02,\n",
      "         -7.5270e-02,  7.1535e-02, -5.0395e-02,  2.2019e-02, -5.9376e-02,\n",
      "          1.6533e-05,  7.4713e-02,  5.8785e-02,  1.3540e-02, -2.0661e-02,\n",
      "          7.8541e-02, -4.1092e-02, -5.3427e-02],\n",
      "        [ 7.2274e-02, -6.1446e-02, -6.1185e-02, -2.1973e-02, -6.6830e-02,\n",
      "          2.3895e-02,  2.3986e-02,  5.4492e-02, -4.9883e-02, -4.2980e-02,\n",
      "         -6.9341e-02,  8.1211e-02, -6.0568e-02,  4.3602e-02,  2.0313e-04,\n",
      "         -8.5021e-02, -6.7685e-02, -5.4608e-02, -1.9797e-02,  4.8994e-02,\n",
      "         -3.7839e-02, -7.0389e-02, -4.7396e-02, -1.2473e-02,  7.3890e-02,\n",
      "         -5.3058e-02, -7.9208e-02,  3.9730e-02,  4.0819e-02,  4.3790e-03,\n",
      "          6.2531e-02, -4.8515e-02, -7.2670e-02,  4.7703e-02,  8.7663e-02,\n",
      "         -1.2908e-02, -1.9399e-02,  9.4544e-04, -6.1427e-03,  1.1464e-02,\n",
      "          7.3867e-02, -4.1296e-02, -4.4946e-02,  7.8219e-02, -7.2977e-02,\n",
      "         -8.5323e-02, -3.7695e-02, -5.4747e-02,  3.5652e-02,  3.8941e-02,\n",
      "         -7.5620e-02,  3.6053e-02,  6.2994e-02, -3.5377e-02,  7.3578e-02,\n",
      "         -6.5212e-02, -6.0774e-02,  6.5501e-03, -2.4650e-02, -1.6518e-02,\n",
      "          3.9463e-02,  4.3432e-02, -1.4646e-02, -8.5737e-02,  2.1616e-02,\n",
      "          5.5710e-02,  4.9213e-02,  4.2523e-02,  1.0326e-02, -7.9884e-02,\n",
      "          7.5046e-02,  3.2811e-02,  1.9324e-02,  7.0736e-02,  1.3809e-02,\n",
      "          2.2586e-02, -1.9714e-02,  8.8328e-02,  6.2506e-02, -5.4429e-04,\n",
      "         -6.2555e-02, -4.4089e-02,  6.2572e-03,  7.6742e-02, -4.1899e-02,\n",
      "         -2.8199e-02, -7.9081e-04, -1.3411e-02, -6.4600e-02, -4.0862e-02,\n",
      "         -6.0452e-02, -8.6395e-02,  5.1411e-02,  6.9176e-02, -1.5946e-02,\n",
      "         -6.2049e-02, -1.3995e-03,  4.9989e-02, -4.7539e-02,  3.9906e-02,\n",
      "         -3.3921e-02,  8.3050e-02,  8.1876e-02, -5.6559e-02,  2.3991e-02,\n",
      "          4.9782e-02, -3.7871e-02, -6.9802e-03, -3.2338e-02,  9.7717e-03,\n",
      "          1.2337e-03,  1.4644e-02,  8.1891e-03,  5.8808e-02, -7.5830e-02,\n",
      "         -6.1984e-02, -1.7678e-02, -6.2461e-02,  5.0799e-02,  1.3673e-02,\n",
      "          6.1301e-02,  5.6968e-02,  2.4065e-02,  8.2030e-02,  5.6071e-02,\n",
      "          7.5860e-02, -5.1762e-02, -5.2472e-03]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0342, -0.0147, -0.0457], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for param in list(model.parameters()):\n",
    "    if(param.requires_grad == True):\n",
    "        print(param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDAM Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LDAMLoss(nn.Module):\n",
    "    \n",
    "    def __init__(self, cls_num_list, max_m=0.5, weight=None, s=30):\n",
    "        super(LDAMLoss, self).__init__()\n",
    "        m_list = 1.0 / np.sqrt(np.sqrt(cls_num_list))\n",
    "        m_list = m_list * (max_m / np.max(m_list))\n",
    "        m_list = torch.cuda.FloatTensor(m_list)\n",
    "        self.m_list = m_list\n",
    "        assert s > 0\n",
    "        self.s = s\n",
    "        self.weight = weight\n",
    "\n",
    "    def forward(self, x, target):\n",
    "        index = torch.zeros_like(x, dtype=torch.uint8)\n",
    "        index.scatter_(1, target.data.view(-1, 1), 1)\n",
    "        \n",
    "        index_float = index.type(torch.cuda.FloatTensor)\n",
    "        batch_m = torch.matmul(self.m_list[None, :], index_float.transpose(0,1))\n",
    "        batch_m = batch_m.view((-1, 1))\n",
    "        x_m = x - batch_m\n",
    "    \n",
    "        output = torch.where(index, x_m, x)\n",
    "        return F.cross_entropy(self.s*output, target, weight=self.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LDAMLoss(output, target, n_class_nil, n_class_MOD, n_class_SEV, C):\n",
    "    loss = 0\n",
    "    n_class = [n_class_nil, n_class_MOD, n_class_SEV]\n",
    "    #output_class = output.argmax(dim=1, keepdim=False) #Shape [64], the predict class\n",
    "    niter = output.shape[0] # 64 for a batch\n",
    "    for i in range(niter):\n",
    "        Z_y = output[i][target[i]]\n",
    "        delta_y = C / (n_class[target[i]] ** (0.25) )\n",
    "        nominator = torch.exp(Z_y - delta_y)\n",
    "        if (target[i] == 0):\n",
    "            dinominator = nominator + torch.exp(output[i][1]) + torch.exp(output[i][2])\n",
    "        elif (target[i] == 1):\n",
    "            dinominator = nominator + torch.exp(output[i][0]) + torch.exp(output[i][2])\n",
    "        else:\n",
    "            dinominator = nominator + torch.exp(output[i][0]) + torch.exp(output[i][1])\n",
    "        loss += (-torch.log(nominator/dinominator))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_acc(outputs, targets):\n",
    "    preds = outputs.argmax(dim=1, keepdim=True)\n",
    "    return preds.eq(targets.view_as(preds)).sum().item() / targets.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def performance_eval(outputs, targets):\n",
    "    preds = outputs.argmax(dim=1, keepdim=False)\n",
    "    targets = targets.view_as(preds)\n",
    "    performance_dict = {\"NIL\":0.0,\"MOD\":0.0, \"SEV\":0.0 }\n",
    "    for i in range(3):\n",
    "        TP = targets[preds.eq(i)].eq(i).sum().item()\n",
    "        FP = (~targets[preds.eq(i)].eq(i)).sum().item()\n",
    "        FN = (~preds[targets.eq(i)].eq(i)).sum().item()\n",
    "        Precision =  torch.true_divide(TP,(TP + FP))\n",
    "        Recall = torch.true_divide(TP,(TP + FN))\n",
    "        F1 = torch.true_divide(2*(Precision*Recall),(Precision+Recall))\n",
    "        performance_dict[list(performance_dict.keys())[i]] = torch.tensor([Precision,Recall,F1])\n",
    "    return performance_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "        \n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.cnt = 0\n",
    "        self.TP = torch.tensor([0,0,0])\n",
    "        self.FP = torch.tensor([0,0,0])\n",
    "        self.FN = torch.tensor([0,0,0])\n",
    "        \n",
    "    def update(self, val, outputs, targets, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.cnt += n\n",
    "        self.avg = self.sum / self.cnt\n",
    "        preds = outputs.argmax(dim=1, keepdim=True)\n",
    "        preds = preds.view(-1)\n",
    "        targets = targets.view(-1)\n",
    "        for i in range(3):\n",
    "            self.TP[i] += targets[preds.eq(i)].eq(i).sum().item()\n",
    "            self.FP[i] += (~targets[preds.eq(i)].eq(i)).sum().item()\n",
    "            self.FN[i] += (~preds[targets.eq(i)].eq(i)).sum().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.cuda()\n",
    "#criterion = criterion.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch():\n",
    "    accs = AverageMeter()\n",
    "    for X, y in tqdm(train_loader, leave=False):\n",
    "        inputs = X.cuda()\n",
    "        targets = y.cuda()\n",
    "        #inputs = X\n",
    "        #targets = y\n",
    "        optimizer.zero_grad()\n",
    "        # forward\n",
    "        outputs = model(inputs)\n",
    "        loss = LDAMLoss(outputs,targets,591,839,324,C = 1.0)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        accs.update(compute_acc(outputs, targets), outputs, targets, X.size(0))\n",
    "        \n",
    "    return accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_one_epoch():\n",
    "    accs = AverageMeter()\n",
    "    for X, y in tqdm(val_loader, leave=False):\n",
    "        inputs = X.cuda()\n",
    "        targets = y.cuda()\n",
    "        #inputs = X\n",
    "        #targets = y\n",
    "        #optimizer.zero_grad()\n",
    "        # forward\n",
    "        outputs = model(inputs)\n",
    "        #loss = criterion(outputs, targets)\n",
    "        loss = LDAMLoss(outputs,targets,192,81,33,C = 1)\n",
    "\n",
    "        #loss.backward()\n",
    "        #optimizer.step()\n",
    "        accs.update(compute_acc(outputs, targets), outputs, targets, X.size(0))\n",
    "    return accs  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de8afc2c2bd647c1b9f0b753f5b0a040",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=50.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b37686d3f3204172bf0ef320637888a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=28.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "tensor should be a torch tensor. Got <class 'PIL.Image.Image'>.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-c787641968ef>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mphase\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m             \u001b[0maccs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_one_epoch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"epoch {} train acc: {:.4f} \"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mavg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m             \u001b[0mclass_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"NIL\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"MOD\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"SEV\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-15-7b7c8a3ae444>\u001b[0m in \u001b[0;36mtrain_one_epoch\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mtrain_one_epoch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0maccs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAverageMeter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mleave\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m         \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mtargets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\comp4901\\lib\\site-packages\\tqdm\\notebook.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    226\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 228\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtqdm_notebook\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__iter__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    229\u001b[0m                 \u001b[1;31m# return super(tqdm...) will not catch exception\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    230\u001b[0m                 \u001b[1;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\comp4901\\lib\\site-packages\\tqdm\\std.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1131\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1132\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1133\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1134\u001b[0m                 \u001b[1;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1135\u001b[0m                 \u001b[1;31m# Update and possibly print the progressbar.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\comp4901\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    361\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    362\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 363\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    364\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    365\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\comp4901\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    401\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    402\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 403\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    404\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    405\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\comp4901\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\comp4901\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Year3F\\COMP4211\\FinalProject\\MyDataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     53\u001b[0m             \u001b[0mcolor_img\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m255\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mcolor_img\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m             \u001b[0mcolor_img\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolor_img\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m             \u001b[0mcolor_img\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolor_img\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcolor_img\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\comp4901\\lib\\site-packages\\torchvision\\transforms\\transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m             \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\comp4901\\lib\\site-packages\\torchvision\\transforms\\transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, tensor)\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mNormalized\u001b[0m \u001b[0mTensor\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m         \"\"\"\n\u001b[1;32m--> 212\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    213\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    214\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\comp4901\\lib\\site-packages\\torchvision\\transforms\\functional.py\u001b[0m in \u001b[0;36mnormalize\u001b[1;34m(tensor, mean, std, inplace)\u001b[0m\n\u001b[0;32m    278\u001b[0m     \"\"\"\n\u001b[0;32m    279\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 280\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'tensor should be a torch tensor. Got {}.'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    281\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    282\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndimension\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: tensor should be a torch tensor. Got <class 'PIL.Image.Image'>."
     ]
    }
   ],
   "source": [
    "best_epoch = -1\n",
    "best_acc = 0.0\n",
    "best_model_state = model.state_dict()\n",
    "history_train_acc = []\n",
    "history_val_acc = []\n",
    "n_epoch = 50\n",
    "\n",
    "for epoch in tqdm(range(n_epoch)):\n",
    "    for phase in range (0,2):\n",
    "        if phase == 0:\n",
    "            model.train()\n",
    "            accs = train_one_epoch()\n",
    "            print(\"epoch {} train acc: {:.4f} \".format(epoch, accs.avg))\n",
    "            class_names = [\"NIL\",\"MOD\",\"SEV\"]\n",
    "            for i in range(3):\n",
    "                Precision =  torch.true_divide(accs.TP[i],(accs.TP[i] + accs.FP[i]))\n",
    "                Recall = torch.true_divide(accs.TP[i],(accs.TP[i] + accs.FN[i]))\n",
    "                F1 = torch.true_divide(2*(Precision*Recall),(Precision+Recall))\n",
    "                print(\"class {} Precision {:.3f} Recall{:.3f} F1 {:.3f}\".format(class_names[i],Precision,Recall,F1))\n",
    "            history_train_acc.append(accs)\n",
    "            scheduler.step()\n",
    "            \n",
    "        elif phase == 1:\n",
    "            model.eval()\n",
    "            accs = validate_one_epoch()\n",
    "            print(\"epoch {} valid acc: {:.4f} \".format(epoch, accs.avg))\n",
    "            class_names = [\"NIL\",\"MOD\",\"SEV\"]\n",
    "            for i in range(3):\n",
    "                Precision =  torch.true_divide(accs.TP[i],(accs.TP[i] + accs.FP[i]))\n",
    "                Recall = torch.true_divide(accs.TP[i],(accs.TP[i] + accs.FN[i]))\n",
    "                F1 = torch.true_divide(2*(Precision*Recall),(Precision+Recall))\n",
    "                print(\"class {} Precision {:.3f} Recall{:.3f} F1 {:.3f}\".format(class_names[i],Precision,Recall,F1))\n",
    "            history_val_acc.append(accs)\n",
    "            \n",
    "            if accs.avg > best_acc:\n",
    "                best_acc = accs.avg\n",
    "                best_epoch = epoch\n",
    "                best_model_state = model.state_dict()   \n",
    "            \n",
    "print(f'[Info] best val acc: {best_acc:.2%} at {best_epoch+1}th epoch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_accuracy = []\n",
    "val_accuracy = []\n",
    "for accs in history_train_acc:\n",
    "    train_accuracy.append(accs.avg)\n",
    "for accs in history_val_acc:\n",
    "    val_accuracy.append(accs.avg)\n",
    "plt.plot(range(n_epoch),train_accuracy)\n",
    "plt.plot(range(n_epoch),val_accuracy)\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train','validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(best_model_state, \"resnet_state_50_batchnorm.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y actual: tensor([0, 1, 2, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 2, 1, 0,\n",
      "        1, 0, 1, 0, 0, 0, 0, 0, 2, 0, 2, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 2, 0, 0,\n",
      "        1, 0, 2, 0, 0, 0, 0, 0, 1, 1, 1, 0, 2, 1, 0, 0])\n",
      "tensor([1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 2, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "        2, 0, 1, 0, 0, 1, 0, 0, 1, 2, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 2, 1, 2,\n",
      "        1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0], device='cuda:0')\n",
      "Test Acc: 0.59375\n",
      "y actual: tensor([1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 2, 0, 0, 0, 1, 1, 0, 0, 0,\n",
      "        2, 0, 0, 1, 0, 0, 1, 1, 2, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0])\n",
      "tensor([0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 2, 0,\n",
      "        1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 2, 0, 1, 1, 1, 1, 0, 0, 0, 0, 2, 0,\n",
      "        0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1], device='cuda:0')\n",
      "Test Acc: 0.703125\n",
      "y actual: tensor([0, 0, 0, 0, 1, 2, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0,\n",
      "        1, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 2, 0, 1, 0, 0, 0, 0, 1, 0, 0,\n",
      "        1, 0, 1, 1, 1, 2, 0, 1, 0, 0, 2, 0, 1, 0, 0, 1])\n",
      "tensor([1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0,\n",
      "        1, 1, 0, 2, 1, 0, 1, 1, 0, 1, 1, 0, 1, 2, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0,\n",
      "        1, 0, 2, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1], device='cuda:0')\n",
      "Test Acc: 0.625\n",
      "y actual: tensor([0, 2, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 2, 2,\n",
      "        0, 0, 1, 0, 0, 1, 2, 2, 1, 1, 2, 0, 0, 0, 1, 1, 0, 2, 1, 0, 0, 2, 0, 1,\n",
      "        2, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0])\n",
      "tensor([0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
      "        0, 0, 1, 1, 0, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1,\n",
      "        2, 2, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0], device='cuda:0')\n",
      "Test Acc: 0.625\n",
      "y actual: tensor([0, 0, 1, 0, 0, 2, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
      "        2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 2, 1, 1, 0, 2, 0, 2, 0, 0, 0, 0, 0,\n",
      "        2, 1])\n",
      "tensor([0, 2, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 2, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0,\n",
      "        1, 0, 1, 1, 0, 0, 2, 0, 0, 0, 1, 0, 1, 1, 1, 1, 2, 1, 1, 1, 0, 1, 0, 0,\n",
      "        0, 1], device='cuda:0')\n",
      "Test Acc: 0.6\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "for X, y in tqdm(val_loader, leave=False):\n",
    "    inputs = X.cuda()\n",
    "    outputs = model(inputs)\n",
    "    print(\"y actual:\",y)\n",
    "    print(outputs.argmax(dim=1, keepdim=True).view(-1))\n",
    "    acc = compute_acc(outputs.cpu(), y)\n",
    "    print(f'Test Acc: {acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, label = train_dataset.__getitem__(1700)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 224, 224])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(30768.3457)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img[0,:,:].sum()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([224, 224, 4])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = torch.tensor(color_img)\n",
    "img = img.permute(1,2,0)\n",
    "img = img/255\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Invalid shape (224, 4, 224) for image data",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-dccd66247700>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\comp4901\\lib\\site-packages\\matplotlib\\pyplot.py\u001b[0m in \u001b[0;36mimshow\u001b[1;34m(X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, filternorm, filterrad, resample, url, data, **kwargs)\u001b[0m\n\u001b[0;32m   2706\u001b[0m         \u001b[0mfilternorm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilterrad\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresample\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2707\u001b[0m         data=None, **kwargs):\n\u001b[1;32m-> 2708\u001b[1;33m     __ret = gca().imshow(\n\u001b[0m\u001b[0;32m   2709\u001b[0m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcmap\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnorm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnorm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maspect\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maspect\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2710\u001b[0m         \u001b[0minterpolation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvmin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvmin\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\comp4901\\lib\\site-packages\\matplotlib\\__init__.py\u001b[0m in \u001b[0;36minner\u001b[1;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1436\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1437\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1438\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msanitize_sequence\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1439\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1440\u001b[0m         \u001b[0mbound\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_sig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\comp4901\\lib\\site-packages\\matplotlib\\axes\\_axes.py\u001b[0m in \u001b[0;36mimshow\u001b[1;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, filternorm, filterrad, resample, url, **kwargs)\u001b[0m\n\u001b[0;32m   5521\u001b[0m                               resample=resample, **kwargs)\n\u001b[0;32m   5522\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5523\u001b[1;33m         \u001b[0mim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5524\u001b[0m         \u001b[0mim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_alpha\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5525\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_clip_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\comp4901\\lib\\site-packages\\matplotlib\\image.py\u001b[0m in \u001b[0;36mset_data\u001b[1;34m(self, A)\u001b[0m\n\u001b[0;32m    703\u001b[0m         if not (self._A.ndim == 2\n\u001b[0;32m    704\u001b[0m                 or self._A.ndim == 3 and self._A.shape[-1] in [3, 4]):\n\u001b[1;32m--> 705\u001b[1;33m             raise TypeError(\"Invalid shape {} for image data\"\n\u001b[0m\u001b[0;32m    706\u001b[0m                             .format(self._A.shape))\n\u001b[0;32m    707\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Invalid shape (224, 4, 224) for image data"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(img.permute(1,2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2.])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.Tensor([[1,2],[2,3]])\n",
    "a[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "from MyDataset import MyDataset\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms, models\n",
    "from torch.nn import functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.optim import lr_scheduler\n",
    "from tqdm.auto import tqdm\n",
    "from PIL import Image\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_transform = transforms.Compose([\n",
    "    #transforms.RandomHorizontalFlip(),\n",
    "    #transforms.ColorJitter(brightness=0.5, contrast=0.5, saturation=0.5),\n",
    "    #transforms.RandomCrop(200),\n",
    "    #transforms.RandomVerticalFlip(),\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MyDataset(\"./train\",pre_transform)\n",
    "val_dataset = MyDataset(\"./validate\",val_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data length: 1754  valid data length  306\n"
     ]
    }
   ],
   "source": [
    "print(\"train data length: %d  valid data length % d\"%(len(train_dataset),len(val_dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Traning Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img,label = train_dataset[0]\n",
    "# if (label == 0):\n",
    "#     print(\"This is class nil\")\n",
    "# elif (label == 1):\n",
    "#     print(\"This is class MOD\")\n",
    "# else:\n",
    "#     print(\"This is class SEV\")\n",
    "\n",
    "# Band8 = img[0][:][:]\n",
    "# Band12 = img[1][:][:]\n",
    "# Band13 = img[2][:][:]\n",
    "# Band14 = img[3][:][:]\n",
    "# Band = [Band8,Band12,Band13,Band14]\n",
    "\n",
    "# for i in range(1,5):\n",
    "#     plt.subplot(2,2,i)\n",
    "#     plt.imshow(Band[i-1])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Calculate the number of samples in differnet class\n",
    "# train_nil_count = 0   ##591\n",
    "# train_MOD_count = 0   ##839\n",
    "# train_SEV_count = 0   ##324\n",
    "# valid_nil_count = 0   ##192\n",
    "# valid_MOD_count = 0   ##81\n",
    "# valid_SEV_count = 0   ##33\n",
    "\n",
    "# for i in range (0,1754):\n",
    "#     #print(i)\n",
    "#     img, label = train_dataset[i]\n",
    "#     if (label == 0):\n",
    "#         train_nil_count += 1\n",
    "#     elif (label == 1):\n",
    "#         train_MOD_count += 1\n",
    "#     else:\n",
    "#         train_SEV_count += 1\n",
    "# print(\"train set has %d nil, %d MOD, %d SEV\" %(train_nil_count, train_MOD_count, train_SEV_count))\n",
    "\n",
    "# for i in range (0,306):\n",
    "#     #print(i)\n",
    "#     img, label = val_dataset[i]\n",
    "#     if (label == 0):\n",
    "#         valid_nil_count += 1\n",
    "#     elif (label == 1):\n",
    "#         valid_MOD_count += 1\n",
    "#     else:\n",
    "#         valid_SEV_count += 1\n",
    "# print(\"valid set has %d nil, %d MOD, %d SEV\" %(valid_nil_count, valid_MOD_count, valid_SEV_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Model & Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(4, 16, 3, 1, 1)\n",
    "        self.conv2 = nn.Conv2d(16, 32, 3, 1, 1)\n",
    "        self.conv3 = nn.Conv2d(32, 64, 3, 1, 1)\n",
    "        self.fc1 = nn.Linear(64*28*28, 2048)\n",
    "        self.fc2 = nn.Linear(2048, 100)\n",
    "        self.fc3 = nn.Linear(100, 3)\n",
    "        self.batchnorm1 = nn.BatchNorm2d(16)\n",
    "        self.batchnorm2 = nn.BatchNorm2d(32)\n",
    "        self.batchnorm23 = nn.BatchNorm2d(64)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.batchnorm3 = nn.BatchNorm1d(2048)\n",
    "        self.batchnorm4 = nn.BatchNorm1d(100)\n",
    "        self.batchnorm5 = nn.BatchNorm1d(3)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x's shape = N * 4 * 224 * 224, where N is batch size\n",
    "        x = self.conv1(x)\n",
    "        # x's shape = N * 16 * 224 * 224\n",
    "        x = self.batchnorm1(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        # x's shape = N * 16 * 112 * 112\n",
    "        x = self.conv2(x)\n",
    "        # x's shape = N * 32 * 112 * 112\n",
    "        x = self.batchnorm2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        # x's shape = N * 32 * 56 * 56\n",
    "        x = self.conv3(x)\n",
    "        x = self.batchnorm23(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = torch.flatten(x, 1) # flat starts from the second dim\n",
    "        # x's shape = N * (32 * 56 * 56) = N * 100352\n",
    "        x = self.fc1(x)\n",
    "        # x's shape =  N * 128\n",
    "        x = self.batchnorm3(x)\n",
    "        x = F.relu(x)\n",
    "        # x =  self.dropout(x)\n",
    "        # x's shape =  N * 128\n",
    "        # x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.batchnorm4(x)\n",
    "        x = F.relu(x)\n",
    "        # x's shape =  N * 3\n",
    "        # x =  self.dropout(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.batchnorm5(x)\n",
    "        # x = F.relu(x)\n",
    "        # x's shape =  N * 3\n",
    "        # x =  self.dropout(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True, pin_memory=False)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=64, shuffle=True, pin_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(4, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (fc1): Linear(in_features=50176, out_features=2048, bias=True)\n",
      "  (fc2): Linear(in_features=2048, out_features=100, bias=True)\n",
      "  (fc3): Linear(in_features=100, out_features=3, bias=True)\n",
      "  (batchnorm1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (batchnorm2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (batchnorm23): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (batchnorm3): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (batchnorm4): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (batchnorm5): BatchNorm1d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = Net()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDAM Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LDAMLoss(nn.Module):\n",
    "    \n",
    "    def __init__(self, cls_num_list, max_m=0.5, weight=None, s=30):\n",
    "        super(LDAMLoss, self).__init__()\n",
    "        m_list = 1.0 / np.sqrt(np.sqrt(cls_num_list))\n",
    "        m_list = m_list * (max_m / np.max(m_list))\n",
    "        m_list = torch.cuda.FloatTensor(m_list)\n",
    "        self.m_list = m_list\n",
    "        assert s > 0\n",
    "        self.s = s\n",
    "        self.weight = weight\n",
    "\n",
    "    def forward(self, x, target):\n",
    "        index = torch.zeros_like(x, dtype=torch.uint8)\n",
    "        index.scatter_(1, target.data.view(-1, 1), 1)\n",
    "        \n",
    "        index_float = index.type(torch.cuda.FloatTensor)\n",
    "        batch_m = torch.matmul(self.m_list[None, :], index_float.transpose(0,1))\n",
    "        batch_m = batch_m.view((-1, 1))\n",
    "        x_m = x - batch_m\n",
    "    \n",
    "        output = torch.where(index, x_m, x)\n",
    "        return F.cross_entropy(self.s*output, target, weight=self.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LDAMLoss(output, target, n_class_nil, n_class_MOD, n_class_SEV, C):\n",
    "    loss = 0\n",
    "    n_class = [n_class_nil, n_class_MOD, n_class_SEV]\n",
    "    #output_class = output.argmax(dim=1, keepdim=False) #Shape [64], the predict class\n",
    "    niter = output.shape[0] # 64 for a batch\n",
    "    for i in range(niter):\n",
    "        Z_y = output[i][target[i]]\n",
    "        delta_y = C / (n_class[target[i]] ** (0.25) )\n",
    "        nominator = torch.exp(Z_y - delta_y)\n",
    "        if (target[i] == 0):\n",
    "            dinominator = nominator + torch.exp(output[i][1]) + torch.exp(output[i][2])\n",
    "        elif (target[i] == 1):\n",
    "            dinominator = nominator + torch.exp(output[i][0]) + torch.exp(output[i][2])\n",
    "        else:\n",
    "            dinominator = nominator + torch.exp(output[i][0]) + torch.exp(output[i][1])\n",
    "        loss += (-torch.log(nominator/dinominator))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_acc(outputs, targets):\n",
    "    preds = outputs.argmax(dim=1, keepdim=True)\n",
    "    return preds.eq(targets.view_as(preds)).sum().item() / targets.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def performance_eval(outputs, targets):\n",
    "    preds = outputs.argmax(dim=1, keepdim=False)\n",
    "    targets = targets.view_as(preds)\n",
    "    performance_dict = {\"NIL\":0.0,\"MOD\":0.0, \"SEV\":0.0 }\n",
    "    for i in range(3):\n",
    "        TP = targets[preds.eq(i)].eq(i).sum().item()\n",
    "        FP = (~targets[preds.eq(i)].eq(i)).sum().item()\n",
    "        FN = (~preds[targets.eq(i)].eq(i)).sum().item()\n",
    "        Precision =  torch.true_divide(TP,(TP + FP))\n",
    "        Recall = torch.true_divide(TP,(TP + FN))\n",
    "        F1 = torch.true_divide(2*(Precision*Recall),(Precision+Recall))\n",
    "        performance_dict[list(performance_dict.keys())[i]] = torch.tensor([Precision,Recall,F1])\n",
    "    return performance_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "        \n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.cnt = 0\n",
    "        self.TP = torch.tensor([0,0,0])\n",
    "        self.FP = torch.tensor([0,0,0])\n",
    "        self.FN = torch.tensor([0,0,0])\n",
    "        \n",
    "    def update(self, val, outputs, targets, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.cnt += n\n",
    "        self.avg = self.sum / self.cnt\n",
    "        preds = outputs.argmax(dim=1, keepdim=True)\n",
    "        preds = preds.view(-1)\n",
    "        targets = targets.view(-1)\n",
    "        for i in range(3):\n",
    "            self.TP[i] += targets[preds.eq(i)].eq(i).sum().item()\n",
    "            self.FP[i] += (~targets[preds.eq(i)].eq(i)).sum().item()\n",
    "            self.FN[i] += (~preds[targets.eq(i)].eq(i)).sum().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.cuda()\n",
    "#criterion = criterion.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(inputs, targets, optimizer):\n",
    "    # accs = AverageMeter()\n",
    "    # for X, y in tqdm(train_loader, leave=False):\n",
    "    # inputs = X.cuda()\n",
    "    # targets = y.cuda()\n",
    "    #inputs = X\n",
    "    #targets = y\n",
    "    optimizer.zero_grad()\n",
    "    # forward\n",
    "    outputs = model(inputs)\n",
    "    loss =  LDAMLoss(outputs,targets,591,839,324,C = 1.0)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    # accs.update(compute_acc(outputs, targets), outputs, targets, X.size(0))\n",
    "        \n",
    "    return loss, outputs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_one_epoch(inputs, targets):\n",
    "    accs = AverageMeter()\n",
    "    # for X, y in tqdm(val_loader, leave=False):\n",
    "    # inputs = X.cuda()\n",
    "    # targets = y.cuda()\n",
    "    #inputs = X\n",
    "    #targets = y\n",
    "    #optimizer.zero_grad()\n",
    "    # forward\n",
    "    outputs = model(inputs)\n",
    "    #loss = criterion(outputs, targets)\n",
    "    loss = LDAMLoss(outputs,targets,192,81,33,C = 1)\n",
    "\n",
    "    #loss.backward()\n",
    "    #optimizer.step()\n",
    "    accs.update(compute_acc(outputs, targets), outputs, targets, X.size(0))\n",
    "    return loss, outputs  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b01cddea67a149d694adc81441c500a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=50.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=28.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 train acc: 0.5405 \n",
      "class NIL Precision 0.710 Recall0.526 F1 0.604\n",
      "class MOD Precision 0.624 Recall0.553 F1 0.586\n",
      "class SEV Precision 0.302 Recall0.534 F1 0.386\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 valid acc: 0.6275 \n",
      "class NIL Precision 0.627 Recall1.000 F1 0.771\n",
      "class MOD Precision nan Recall0.000 F1 nan\n",
      "class SEV Precision nan Recall0.000 F1 nan\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f33e557f92246c0a6ac595d742ce4a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=28.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 392.00 MiB (GPU 0; 6.00 GiB total capacity; 3.88 GiB already allocated; 30.63 MiB free; 4.13 GiB reserved in total by PyTorch)\nException raised from malloc at ..\\c10\\cuda\\CUDACachingAllocator.cpp:272 (most recent call first):\n00007FFC2B0E75A200007FFC2B0E7540 c10.dll!c10::Error::Error [<unknown file> @ <unknown line number>]\n00007FFC2B089C0600007FFC2B089B90 c10_cuda.dll!c10::CUDAOutOfMemoryError::CUDAOutOfMemoryError [<unknown file> @ <unknown line number>]\n00007FFC2B09069600007FFC2B08F370 c10_cuda.dll!c10::cuda::CUDACachingAllocator::init [<unknown file> @ <unknown line number>]\n00007FFC2B09083A00007FFC2B08F370 c10_cuda.dll!c10::cuda::CUDACachingAllocator::init [<unknown file> @ <unknown line number>]\n00007FFC2B08509900007FFC2B084EB0 c10_cuda.dll!c10::cuda::CUDAStream::unpack [<unknown file> @ <unknown line number>]\n00007FFBE9F51FF100007FFBE9F51EB0 torch_cuda.dll!at::native::empty_cuda [<unknown file> @ <unknown line number>]\n00007FFBEA068AFE00007FFBEA00E0A0 torch_cuda.dll!at::native::set_storage_cuda_ [<unknown file> @ <unknown line number>]\n00007FFBEA0642A500007FFBEA00E0A0 torch_cuda.dll!at::native::set_storage_cuda_ [<unknown file> @ <unknown line number>]\n00007FFBE2061A3A00007FFBE204D9D0 torch_cpu.dll!at::native::mkldnn_sigmoid_ [<unknown file> @ <unknown line number>]\n00007FFBE206000500007FFBE204D9D0 torch_cpu.dll!at::native::mkldnn_sigmoid_ [<unknown file> @ <unknown line number>]\n00007FFBE21318A000007FFBE2128FA0 torch_cpu.dll!at::bucketize_out [<unknown file> @ <unknown line number>]\n00007FFBE21428DC00007FFBE2142850 torch_cpu.dll!at::empty [<unknown file> @ <unknown line number>]\n00007FFBE950F5E400007FFBE950F560 torch_cuda.dll!at::native::mm_cuda [<unknown file> @ <unknown line number>]\n00007FFBEA071B0F00007FFBEA00E0A0 torch_cuda.dll!at::native::set_storage_cuda_ [<unknown file> @ <unknown line number>]\n00007FFBEA061B2200007FFBEA00E0A0 torch_cuda.dll!at::native::set_storage_cuda_ [<unknown file> @ <unknown line number>]\n00007FFBE212D94900007FFBE2128FA0 torch_cpu.dll!at::bucketize_out [<unknown file> @ <unknown line number>]\n00007FFBE216057700007FFBE2160520 torch_cpu.dll!at::mm [<unknown file> @ <unknown line number>]\n00007FFBE34BEC7900007FFBE33CE010 torch_cpu.dll!torch::autograd::GraphRoot::apply [<unknown file> @ <unknown line number>]\n00007FFBE1C7715700007FFBE1C76290 torch_cpu.dll!at::indexing::TensorIndex::boolean [<unknown file> @ <unknown line number>]\n00007FFBE212D94900007FFBE2128FA0 torch_cpu.dll!at::bucketize_out [<unknown file> @ <unknown line number>]\n00007FFBE224210700007FFBE22420B0 torch_cpu.dll!at::Tensor::mm [<unknown file> @ <unknown line number>]\n00007FFBE335B96900007FFBE335A760 torch_cpu.dll!torch::autograd::profiler::Event::kind [<unknown file> @ <unknown line number>]\n00007FFBE33117EC00007FFBE3311580 torch_cpu.dll!torch::autograd::generated::AddmmBackward::apply [<unknown file> @ <unknown line number>]\n00007FFBE3307E9100007FFBE3307B50 torch_cpu.dll!torch::autograd::Node::operator() [<unknown file> @ <unknown line number>]\n00007FFBE386F9BA00007FFBE386F300 torch_cpu.dll!torch::autograd::Engine::add_thread_pool_task [<unknown file> @ <unknown line number>]\n00007FFBE38703AD00007FFBE386FFD0 torch_cpu.dll!torch::autograd::Engine::evaluate_function [<unknown file> @ <unknown line number>]\n00007FFBE3874FE200007FFBE3874CA0 torch_cpu.dll!torch::autograd::Engine::thread_main [<unknown file> @ <unknown line number>]\n00007FFBE3874C4100007FFBE3874BC0 torch_cpu.dll!torch::autograd::Engine::thread_init [<unknown file> @ <unknown line number>]\n00007FFBAA4808F700007FFBAA459F80 torch_python.dll!THPShortStorage_New [<unknown file> @ <unknown line number>]\n00007FFBE386BF1400007FFBE386B780 torch_cpu.dll!torch::autograd::Engine::get_base_engine [<unknown file> @ <unknown line number>]\n00007FFC750110B200007FFC75010F70 ucrtbase.dll!beginthreadex [<unknown file> @ <unknown line number>]\n00007FFC752E7C2400007FFC752E7C10 KERNEL32.DLL!BaseThreadInitThunk [<unknown file> @ <unknown line number>]\n00007FFC7722D4D100007FFC7722D4B0 ntdll.dll!RtlUserThreadStart [<unknown file> @ <unknown line number>]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-9039d4a7cfc8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m                 \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m                 \u001b[0mtargets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m                 \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_one_epoch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m                 \u001b[0maccs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcompute_acc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"epoch {} train acc: {:.4f} \"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mavg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-18-1b67f35719fa>\u001b[0m in \u001b[0;36mtrain_one_epoch\u001b[1;34m(inputs, targets, optimizer)\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0mLDAMLoss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtargets\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m591\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m839\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m324\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mC\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1.0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[1;31m# accs.update(compute_acc(outputs, targets), outputs, targets, X.size(0))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\comp4901\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    183\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m         \"\"\"\n\u001b[1;32m--> 185\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    186\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\comp4901\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m    123\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 125\u001b[1;33m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[0;32m    126\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    127\u001b[0m         allow_unreachable=True)  # allow_unreachable flag\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 392.00 MiB (GPU 0; 6.00 GiB total capacity; 3.88 GiB already allocated; 30.63 MiB free; 4.13 GiB reserved in total by PyTorch)\nException raised from malloc at ..\\c10\\cuda\\CUDACachingAllocator.cpp:272 (most recent call first):\n00007FFC2B0E75A200007FFC2B0E7540 c10.dll!c10::Error::Error [<unknown file> @ <unknown line number>]\n00007FFC2B089C0600007FFC2B089B90 c10_cuda.dll!c10::CUDAOutOfMemoryError::CUDAOutOfMemoryError [<unknown file> @ <unknown line number>]\n00007FFC2B09069600007FFC2B08F370 c10_cuda.dll!c10::cuda::CUDACachingAllocator::init [<unknown file> @ <unknown line number>]\n00007FFC2B09083A00007FFC2B08F370 c10_cuda.dll!c10::cuda::CUDACachingAllocator::init [<unknown file> @ <unknown line number>]\n00007FFC2B08509900007FFC2B084EB0 c10_cuda.dll!c10::cuda::CUDAStream::unpack [<unknown file> @ <unknown line number>]\n00007FFBE9F51FF100007FFBE9F51EB0 torch_cuda.dll!at::native::empty_cuda [<unknown file> @ <unknown line number>]\n00007FFBEA068AFE00007FFBEA00E0A0 torch_cuda.dll!at::native::set_storage_cuda_ [<unknown file> @ <unknown line number>]\n00007FFBEA0642A500007FFBEA00E0A0 torch_cuda.dll!at::native::set_storage_cuda_ [<unknown file> @ <unknown line number>]\n00007FFBE2061A3A00007FFBE204D9D0 torch_cpu.dll!at::native::mkldnn_sigmoid_ [<unknown file> @ <unknown line number>]\n00007FFBE206000500007FFBE204D9D0 torch_cpu.dll!at::native::mkldnn_sigmoid_ [<unknown file> @ <unknown line number>]\n00007FFBE21318A000007FFBE2128FA0 torch_cpu.dll!at::bucketize_out [<unknown file> @ <unknown line number>]\n00007FFBE21428DC00007FFBE2142850 torch_cpu.dll!at::empty [<unknown file> @ <unknown line number>]\n00007FFBE950F5E400007FFBE950F560 torch_cuda.dll!at::native::mm_cuda [<unknown file> @ <unknown line number>]\n00007FFBEA071B0F00007FFBEA00E0A0 torch_cuda.dll!at::native::set_storage_cuda_ [<unknown file> @ <unknown line number>]\n00007FFBEA061B2200007FFBEA00E0A0 torch_cuda.dll!at::native::set_storage_cuda_ [<unknown file> @ <unknown line number>]\n00007FFBE212D94900007FFBE2128FA0 torch_cpu.dll!at::bucketize_out [<unknown file> @ <unknown line number>]\n00007FFBE216057700007FFBE2160520 torch_cpu.dll!at::mm [<unknown file> @ <unknown line number>]\n00007FFBE34BEC7900007FFBE33CE010 torch_cpu.dll!torch::autograd::GraphRoot::apply [<unknown file> @ <unknown line number>]\n00007FFBE1C7715700007FFBE1C76290 torch_cpu.dll!at::indexing::TensorIndex::boolean [<unknown file> @ <unknown line number>]\n00007FFBE212D94900007FFBE2128FA0 torch_cpu.dll!at::bucketize_out [<unknown file> @ <unknown line number>]\n00007FFBE224210700007FFBE22420B0 torch_cpu.dll!at::Tensor::mm [<unknown file> @ <unknown line number>]\n00007FFBE335B96900007FFBE335A760 torch_cpu.dll!torch::autograd::profiler::Event::kind [<unknown file> @ <unknown line number>]\n00007FFBE33117EC00007FFBE3311580 torch_cpu.dll!torch::autograd::generated::AddmmBackward::apply [<unknown file> @ <unknown line number>]\n00007FFBE3307E9100007FFBE3307B50 torch_cpu.dll!torch::autograd::Node::operator() [<unknown file> @ <unknown line number>]\n00007FFBE386F9BA00007FFBE386F300 torch_cpu.dll!torch::autograd::Engine::add_thread_pool_task [<unknown file> @ <unknown line number>]\n00007FFBE38703AD00007FFBE386FFD0 torch_cpu.dll!torch::autograd::Engine::evaluate_function [<unknown file> @ <unknown line number>]\n00007FFBE3874FE200007FFBE3874CA0 torch_cpu.dll!torch::autograd::Engine::thread_main [<unknown file> @ <unknown line number>]\n00007FFBE3874C4100007FFBE3874BC0 torch_cpu.dll!torch::autograd::Engine::thread_init [<unknown file> @ <unknown line number>]\n00007FFBAA4808F700007FFBAA459F80 torch_python.dll!THPShortStorage_New [<unknown file> @ <unknown line number>]\n00007FFBE386BF1400007FFBE386B780 torch_cpu.dll!torch::autograd::Engine::get_base_engine [<unknown file> @ <unknown line number>]\n00007FFC750110B200007FFC75010F70 ucrtbase.dll!beginthreadex [<unknown file> @ <unknown line number>]\n00007FFC752E7C2400007FFC752E7C10 KERNEL32.DLL!BaseThreadInitThunk [<unknown file> @ <unknown line number>]\n00007FFC7722D4D100007FFC7722D4B0 ntdll.dll!RtlUserThreadStart [<unknown file> @ <unknown line number>]\n"
     ]
    }
   ],
   "source": [
    "best_epoch = -1\n",
    "best_acc = 0.0\n",
    "best_model_state = model.state_dict()\n",
    "history_train_acc = []\n",
    "history_val_acc = []\n",
    "\n",
    "scheduler = lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "\n",
    "for epoch in tqdm(range(50)):\n",
    "    for phase in range (0,2):\n",
    "        if phase == 0:\n",
    "            model.train()\n",
    "            accs = AverageMeter()\n",
    "            for X, y in tqdm(train_loader, leave=False):\n",
    "                inputs = Variable(X.cuda())\n",
    "                targets = Variable(y.cuda())\n",
    "                loss, outputs = train_one_epoch(inputs, targets, optimizer)\n",
    "                accs.update(compute_acc(outputs, targets), outputs, targets, X.size(0))\n",
    "            print(\"epoch {} train acc: {:.4f} \".format(epoch, accs.avg))\n",
    "            class_names = [\"NIL\",\"MOD\",\"SEV\"]\n",
    "            scheduler.step()\n",
    "            for i in range(3):\n",
    "                Precision =  torch.true_divide(accs.TP[i],(accs.TP[i] + accs.FP[i]))\n",
    "                Recall = torch.true_divide(accs.TP[i],(accs.TP[i] + accs.FN[i]))\n",
    "                F1 = torch.true_divide(2*(Precision*Recall),(Precision+Recall))\n",
    "                print(\"class {} Precision {:.3f} Recall{:.3f} F1 {:.3f}\".format(class_names[i],Precision,Recall,F1))\n",
    "            history_train_acc.append(accs)\n",
    "            \n",
    "        elif phase == 1:\n",
    "            model.eval()\n",
    "            accs = AverageMeter()\n",
    "            for X, y in tqdm(val_loader, leave=False):\n",
    "                inputs = Variable(X.cuda())\n",
    "                targets = Variable(y.cuda())\n",
    "                loss, outputs = validate_one_epoch(inputs, targets)\n",
    "                accs.update(compute_acc(outputs, targets), outputs, targets, X.size(0))\n",
    "            print(\"epoch {} valid acc: {:.4f} \".format(epoch, accs.avg))\n",
    "            class_names = [\"NIL\",\"MOD\",\"SEV\"]\n",
    "            for i in range(3):\n",
    "                Precision =  torch.true_divide(accs.TP[i],(accs.TP[i] + accs.FP[i]))\n",
    "                Recall = torch.true_divide(accs.TP[i],(accs.TP[i] + accs.FN[i]))\n",
    "                F1 = torch.true_divide(2*(Precision*Recall),(Precision+Recall))\n",
    "                print(\"class {} Precision {:.3f} Recall{:.3f} F1 {:.3f}\".format(class_names[i],Precision,Recall,F1))\n",
    "            history_val_acc.append(accs)\n",
    "            \n",
    "            if accs.avg > best_acc:\n",
    "                best_acc = accs.avg\n",
    "                best_epoch = epoch\n",
    "                best_model_state = model.state_dict().copy()\n",
    "            \n",
    "print(f'[Info] best val acc: {best_acc:.2%} at {best_epoch+1}th epoch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_accuracy = []\n",
    "val_accuracy = []\n",
    "for accs in history_train_acc:\n",
    "    train_accuracy.append(accs.avg)\n",
    "for accs in history_val_acc:\n",
    "    val_accuracy.append(accs.avg)\n",
    "plt.plot(range(50),train_accuracy)\n",
    "plt.plot(range(50),val_accuracy)\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train','validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(best_model_state, \"3CNN3FC.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(\"Baseline1&2_state.tar\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "for X, y in tqdm(val_loader, leave=False):\n",
    "    inputs = X.cuda()\n",
    "    outputs = model(inputs)\n",
    "    print(\"y actual:\",y)\n",
    "    print(outputs.argmax(dim=1, keepdim=True).view(-1))\n",
    "    acc = compute_acc(outputs.cpu(), y)\n",
    "    print(f'Test Acc: {acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_evaluation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_evaluation():\n",
    "    model.eval()\n",
    "    accs = AverageMeter()\n",
    "    for X, y in tqdm(train_loader, leave=False):\n",
    "        inputs = X.cuda()\n",
    "        targets = y.cuda()\n",
    "        outputs = model(inputs)\n",
    "        accs.update(compute_acc(outputs, targets), outputs, targets, X.size(0))\n",
    "    print(\"train acc: {:.4f} \".format(accs.avg))\n",
    "    class_names = [\"NIL\",\"MOD\",\"SEV\"]\n",
    "    for i in range(3):\n",
    "        Precision =  torch.true_divide(accs.TP[i],(accs.TP[i] + accs.FP[i]))\n",
    "        Recall = torch.true_divide(accs.TP[i],(accs.TP[i] + accs.FN[i]))\n",
    "        F1 = torch.true_divide(2*(Precision*Recall),(Precision+Recall))\n",
    "        print(\"class {} Precision {:.3f} Recall{:.3f} F1 {:.3f}\".format(class_names[i],Precision,Recall,F1))\n",
    "        \n",
    "    accs = AverageMeter()\n",
    "    for X, y in tqdm(val_loader, leave=False):\n",
    "        inputs = X.cuda()\n",
    "        targets = y.cuda()\n",
    "        outputs = model(inputs)\n",
    "        accs.update(compute_acc(outputs, targets), outputs, targets, X.size(0))\n",
    "    print(\"validation acc: {:.4f} \".format(accs.avg))\n",
    "    class_names = [\"NIL\",\"MOD\",\"SEV\"]\n",
    "    for i in range(3):\n",
    "        Precision =  torch.true_divide(accs.TP[i],(accs.TP[i] + accs.FP[i]))\n",
    "        Recall = torch.true_divide(accs.TP[i],(accs.TP[i] + accs.FN[i]))\n",
    "        F1 = torch.true_divide(2*(Precision*Recall),(Precision+Recall))\n",
    "        print(\"class {} Precision {:.3f} Recall{:.3f} F1 {:.3f}\".format(class_names[i],Precision,Recall,F1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, label = train_dataset.__getitem__(1700)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"train/severe_HS_H08_20180124_0400_33.98652512_104.272.npy.pickle\", 'rb') as f:\n",
    "    color_img = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = torch.tensor(color_img)\n",
    "img = img.permute(1,2,0)\n",
    "img = img/255\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img.permute(1,2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
